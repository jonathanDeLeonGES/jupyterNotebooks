{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensayo - Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepto \n",
    "\n",
    "Support Vector Machine  (SVM) son un conjunto de métodos de aprendizaje supervisado utilizados para la clasificación, regresión y detección de valores atípicos. El SVM básico toma un conjunto de datos de entrada y predice, para cada entrada dada, a cuál de las dos clases de salida pertenece, por lo que es un clasificador no-probabilístico lineal binario (solo escoge entre 2 opciones). \n",
    "\n",
    "Si bien originariamente se desarrolló como un método de clasificación binaria, su aplicación se ha extendido a problemas de clasificación múltiple y regresión. SVM ha resultado ser uno de los mejores clasificadores para un amplio abanico de situaciones, por lo que se considera uno de los referentes dentro del ámbito de aprendizaje estadístico y machine learning.\n",
    "\n",
    "SVMs se fundamentan en el Maximal Margin Classifier, que a su vez, se basa en el concepto de hiperplano.*(Ambos conceptos se explican más adelante)*.\n",
    "\n",
    "\n",
    "Las ventajas de las máquinas de vectores de soporte son:\n",
    "* Efectivo en espacios de altas dimensiones.\n",
    "* Sigue siendo efectivo en casos donde el número de dimensiones es mayor que el número de muestras.\n",
    "* Utiliza un subconjunto de puntos de entrenamiento en la función de decisión (llamados vectores de soporte), por lo que también es eficiente en la memoria.\n",
    "* Versátil: se pueden especificar diferentes funciones de Kernel para la función de decisión. Se proporcionan núcleos comunes, pero también es posible especificar núcleos personalizados.\n",
    "\n",
    "Las desventajas de las máquinas de vectores de soporte incluyen:\n",
    "* Si el número de características es mucho mayor que el número de muestras, evite el ajuste excesivo al elegir las funciones del núcleo y el término de regularización es crucial.\n",
    "* Los SVM no proporcionan directamente estimaciones de probabilidad, estas se calculan utilizando una costosa validación cruzada de cinco veces (ver Puntajes y probabilidades, a continuación).\n",
    "* No muy eficiente en muestras con muchos datos, dado el tiempo de procesamiento del algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperplano \n",
    "\n",
    "En SVM se traza cada observación como un punto en un espacio dimensional *n* donde *n* es el número de características que tenemos. El valor de cada característica es el valor de coordenadas particulares. Luego se intenta encontrar un hiper-plano que separe muy bien dos clases.\n",
    "\n",
    "<img src=\"svm_assets/ImageSVM_1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de identificar el mejor hiper-plano, buscaremos agregar márgenes que ayudarían a separar más aún las dos clases.\n",
    "\n",
    "<img src=\"svm_assets/ImageSVM_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM es muy efectivo cuando el número de características es muy alto o si el número de características es más mayor al número de muestras de datos. Aunque, debido a que SVM funciona normalmente con vectores, es crucial normalizar los datos antes de usarlos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El hecho de que los grupos no sean linealmente separables en el espacio original no significa que no lo sean en un espacio de mayores dimensiones. Las imágenes siguientes muestran como dos grupos, cuya separación en dos dimensiones no es lineal, sí lo es al añadir una tercera dimensión.\n",
    "\n",
    "<img src=\"svm_assets/ImageSVM_3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Lineal\n",
    "\n",
    "Comencemos desde SVM lineal que se conoce como SVM sin núcleos (kernels). Mirando el diagrama de dispersión por dos características X1, X2 como se muestra a continuación. En realidad, separamos dos clases de muchas maneras diferentes, la línea rosa y la línea verde son dos de ellas. SVM termina eligiendo la línea verde como límite de decisión, porque la forma en que SVM clasifica las muestras es encontrar el límite de decisión con el margen más grande que es la distancia más grande de una muestra que está más cerca del límite de decisión. Es por eso que **Linear SVM** también se llama Clasificador de margen grande *(Large Margin Classifier)*.\n",
    "\n",
    "<img src=\"svm_assets/ImageSVM_4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*¿Quiénes son los vectores de soporte?* El vector de soporte es una muestra que está clasificada incorrectamente o una muestra cercana a un límite. Mirando la trama a continuación. Las muestras con círculos rojos son exactamente el límite de decisión. En SVM, solo los vectores de soporte tienen un impacto efectivo en el entrenamiento del modelo, es decir, eliminar el vector sin soporte no tiene ningún efecto en el modelo. \n",
    "\n",
    "<img src=\"svm_assets/ImageSVM_5.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de Hipotesis\n",
    "\n",
    "La función de hipotesis para SVM no es mas que:\n",
    "\n",
    "$$h_\\theta(x) = \\left\\{\n",
    "                \\begin{array}\\\\\n",
    "                    1 & \\mbox{si } \\ \\theta^Tx >= 0 \\\\\n",
    "                    0 & \\mbox{otherwise } \n",
    "                \\end{array}\n",
    "             \\right.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de Costo (Hinge Loss)\n",
    "\n",
    "La función de pérdida de SVM es muy similar a la de Regresión logística. Mirándolo por y = 1 e y = 0 por separado en la siguiente gráfica, la línea negra es la función de costo de la Regresión logística, y la línea roja es para SVM. Tenga en cuenta que el eje X aquí es la salida del modelo en bruto, **θᵀx**. Recuerde que poner la salida del modelo en bruto en la función Sigmoide nos da la hipótesis de la regresión logística. ¿Cuál es la hipótesis para SVM? Es simple y directo. Cuando **θᵀx ≥ 0**, predice 1, de lo contrario, predice 0.\n",
    "\n",
    "<img src=\"svm_assets/ImageSVM_6.png\">\n",
    " \n",
    "SVM castiga tanto las predicciones incorrectas como las cercanas al límite de decisión (0 <θᵀx <1), así es como los llamamos vectores de soporte. \n",
    " \n",
    "Escribamos la formula de la función de costo:\n",
    "$$Cost(h_\\theta(x),y) = \\left\\{\n",
    "                \\begin{array}\\\\\n",
    "                    max(0,1-\\theta^Tx) & \\mbox{si } \\ y = 1 \\\\\n",
    "                    max(0,1+\\theta^Tx) & \\mbox{si } \\ y = 0 \\\\\n",
    "                \\end{array}\n",
    "             \\right.$$\n",
    "\n",
    "\n",
    "\n",
    "$$ J(w,b) = 1/2w^tw + c\\sum^n_{i=0}max\\{0,1 - X^0 (w^tx^0 + b)\\} $$\n",
    "\n",
    "donde\n",
    "\n",
    "$$t^{(0)} = \\left\\{\n",
    "                \\begin{array}\\\\\n",
    "                    1 & \\mbox{si } \\ y^{i} = 1 \\\\\n",
    "                    -1 & \\mbox{si } \\ y^{i} = 0 \\\\\n",
    "                \\end{array}\n",
    "             \\right.$$\n",
    "\n",
    "i = 1,2,......m indexa los ejemplos.\n",
    "\n",
    "Función de Costo obtenida del video:  \n",
    "https://www.youtube.com/watch?v=geI6lM5iOl0&feature=youtu.be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Espero completarlo en algunas horas, pero si se reviso antes; pues de igual forma, lo intente :).\n",
    "\n",
    "Me centre en el proyecto, por ende esto lo deje en la última prioridad, si esto no esta completo a la hora de revisión; fue que ya no lo realice.\n",
    "\n",
    "Dejo esta nota para que la persona que revise, no crea que el Link este malo :)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
