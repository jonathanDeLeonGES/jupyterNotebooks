{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practica # 1 - Tensorflow - Gradient Descent y Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos de Proyecto - Carga\n",
    "\n",
    "Se cargará el Dataset del Proyecto del Curso **\"Ciencia de Datos en Python\"**; para referencia se coloca el listado de variables que contiene el Dataset:\n",
    "* **SalePrice:** The property's sale price in dollars. This is the target variable that you're trying to predict.\n",
    "* **OverallQual:** Overall material and finish quality, rates the overall material and finish of the house\n",
    "       10\tVery Excellent\n",
    "       9\tExcellent\n",
    "       8\tVery Good\n",
    "       7\tGood\n",
    "       6\tAbove Average\n",
    "       5\tAverage\n",
    "       4\tBelow Average\n",
    "       3\tFair\n",
    "       2\tPoor\n",
    "       1\tVery Poor\n",
    "* **1stFlrSF:** First Floor square feet\n",
    "* **TotRmsAbvGrd:** Total rooms above grade (does not include bathrooms)\n",
    "* **YearBuilt:** Original construction date\n",
    "* **LotFrontage:** Linear feet of street connected to property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rango Tensor: 2\n",
      "Forma Tensor: (1460, 6)\n",
      "Vemos Primer Registro: [2.085e+05 7.000e+00 8.560e+02 8.000e+00 2.003e+03 6.500e+01]\n"
     ]
    }
   ],
   "source": [
    "#Importamos Libreria de Numpy para cargar los datos\n",
    "import numpy as np\n",
    "\n",
    "House_Data = np.load('proyecto_data/proyecto_training_data.npy')\n",
    "\n",
    "##Verificamos que haya cargado la información, y que tenga la forma requerida\n",
    "print('Rango Tensor:',House_Data.ndim)\n",
    "print('Forma Tensor:',House_Data.shape)\n",
    "print('Vemos Primer Registro:',House_Data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos de Entrenamiento\n",
    "\n",
    "Consideremos lo siguiente:\n",
    "* La variable Dependiente seguirá siendo **\"SalesPrice\"**\n",
    "* La variable Independiente (FEATURE) será **\"OverallQual\"** que demostró una mayor correlación para el proyecto pasado.\n",
    "* Tomaremos todo el Dataset para Entrenamiento, esta vez no separaremos el Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Por Facilidad se manejaran tensores quitando los datos que no utilizaremos\n",
    "##OverallQual - Variable Independiente (FEATURE)\n",
    "x_train = House_Data[:,1]\n",
    "\n",
    "##Valor de Ventas Real -  Variable Dependiente\n",
    "##Al Igual que el Proyecto por facilidad dividiremos por 1000 el precio de las casas\n",
    "y_real = House_Data[:,0]/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow - Definición Modelo\n",
    "\n",
    "Importamos las librerias y ejecutamos los comandos requeridos para utilizar tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jonathan.deleon\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Enabled compatitility to tf1.x\n"
     ]
    }
   ],
   "source": [
    "if tf.__version__.startswith(\"2.\"):\n",
    "  import tensorflow.compat.v1 as tf\n",
    "  tf.compat.v1.disable_v2_behavior()\n",
    "  tf.compat.v1.disable_eager_execution()\n",
    "  print(\"Enabled compatitility to tf1.x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la Clase que almacenará la definición del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Clase que Definirá el Modelo a Entrenar'''\n",
    "class Modelo:\n",
    "    \n",
    "    '''Metodo que define lo que se ejecuta al Instanciar la Clase'''\n",
    "    def __init__(self):\n",
    "        \n",
    "        #Limpiamos cualquier variable o operación en el grafo \n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        #Variables que \"Entrenará\" el Modelo\n",
    "        self.m = tf.get_variable(\"pendiente\",dtype=tf.float32,shape=[],initializer=tf.zeros_initializer())\n",
    "        self.b = tf.get_variable(\"intercepto\",dtype=tf.float32,shape=[],initializer=tf.zeros_initializer())\n",
    "\n",
    "        ##Definimos los Tensores para la Inicialización de Variables\n",
    "        with tf.name_scope(\"Inicializacion\"):\n",
    "            init_global = tf.global_variables_initializer()\n",
    "            init_local = tf.local_variables_initializer()\n",
    "            self.init = tf.group(init_global,init_local)\n",
    "    \n",
    "    '''Metodo que define el Modelo de Predicción'''    \n",
    "    def __call__(self,x):\n",
    "        ##Definimos el Modelo de Predicción\n",
    "        with tf.name_scope(\"Modelo\"):\n",
    "            #lo almacenamos en la propiedad de la clase self.y_hat para que pueda reutilizarse en los otros metodos\n",
    "            #y no llamarlos varias veces - creando multiples instancias del modelo en tensorboard\n",
    "            self.y_hat = tf.add(tf.multiply(self.m,x),self.b,name=\"Prediccion_Modelo\")\n",
    "        return self.y_hat\n",
    "    \n",
    "    '''Metodo que define la Función de Error del Modelo''' \n",
    "    def error_function(self,y,y_hat):\n",
    "        ##Definimos la función de Error\n",
    "        with tf.name_scope(\"Error\"):\n",
    "            #lo almacenamos en la propiedad de la clase self.error para que pueda reutilizarse en los otros metodos\n",
    "            #y no llamarlos varias veces - creando multiples instancias del modelo en tensorboard\n",
    "            self.error = 1/2*tf.reduce_mean(tf.math.square(y - y_hat) )\n",
    "        return self.error\n",
    "    \n",
    "    '''Metodo que define como se actualizan las variables que se entrenan en el Modelo''' \n",
    "    def actualizar(self,x,y,learning_rate):\n",
    "        #Quitamos esto - Para no crear multiples tensores con el modelo de predicción\n",
    "        #y_hat = self(x) \n",
    "    \n",
    "        #Quitamos esto - Para no crear multiples tensores con el modelo de Error\n",
    "        #error = self.error_function(y,self.y_hat)\n",
    "        \n",
    "        #Calculo de la Gradiente - Para variables de Pendiente e Intercepto\n",
    "        with tf.name_scope(\"Calculo_Gradiente\"):\n",
    "            gradiente = tf.gradients(self.error,[self.m, self.b])\n",
    "        \n",
    "        #Actualización de Variables del Modelo - Definición Tensores\n",
    "        with tf.name_scope(\"Act_Parametros_Modelo\"):\n",
    "            actualizacion_m = tf.assign(self.m, self.m - learning_rate*gradiente[0] )\n",
    "            actualizacion_b = tf.assign(self.b, self.b - learning_rate*gradiente[1] )\n",
    "            actualizacion_parametros = tf.group(actualizacion_m,actualizacion_b)\n",
    "\n",
    "        return actualizacion_parametros\n",
    "    \n",
    "    '''Metodo que define el Scalar para Tensorboard'''\n",
    "    def summary(self,x,y):\n",
    "        #Quitamos esto - Para no crear multiples tensores con el modelo de predicción\n",
    "        #self.y_hat = self(x)\n",
    "        \n",
    "        #Quitamos esto - Para no crear multiples tensores con el modelo de Error\n",
    "        #error = self.error_function(y,self.y_hat)\n",
    "        \n",
    "        #Creamos el Tensor con la Información del Scalar\n",
    "        MSE_summary = tf.summary.scalar(name='MSE_Function', tensor=self.error)\n",
    "        return MSE_summary\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la Función de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def Entrenamiento(learning_rate,epochs,imprimir_cada,x,y):\n",
    "    #Instanciamos la Clase que define el Modelo\n",
    "    modelo = Modelo()\n",
    "\n",
    "    #string de configuración para almacenamiento del Grafo\n",
    "    string_conf= time.strftime(\"%Y%m%d\") + \"_\"+time.strftime(\"%H%M%S\")+\"_Batch_GradientDescent_Lr=\"+str(learning_rate)\n",
    "\n",
    "    #Definimos los Placeholders que almacenarán los datos de Entrenamiento del Modelo\n",
    "    tensor_x = tf.placeholder(tf.float32,[x.shape[0]],name=\"tensor_x\")\n",
    "    tensor_y = tf.placeholder(tf.float32,[x.shape[0]],name=\"tensor_y\")\n",
    "\n",
    "    #Llamamos a la función que define el modelo de Predicción\n",
    "    prediccion = modelo(tensor_x)\n",
    "\n",
    "    #Llamamos a la función que define la Función de Error (Costo)\n",
    "    funcion_error = modelo.error_function(prediccion,tensor_y)\n",
    "\n",
    "    #Llamamos a la función que define los tensores para actualizar las variables del Modelo\n",
    "    actualizacion_parametros = modelo.actualizar(tensor_x,tensor_y,learning_rate)\n",
    "\n",
    "    #llamamos a la función que define el Scalar a Reportar en Tensorboard\n",
    "    MSE_summary = modelo.summary(tensor_x,tensor_y)\n",
    "\n",
    "    #Iniciamos con una Sesión Monitoreada - Para el Entrenamiento del Modelo\n",
    "    with tf.train.MonitoredSession() as session:\n",
    "\n",
    "        # Inicialización de variables Globales y locales\n",
    "        session.run(modelo.init)\n",
    "\n",
    "        #Escritura del Grafo para Tensorboard\n",
    "        writer = tf.summary.FileWriter('./graphs/'+string_conf, session.graph)\n",
    "\n",
    "        #Creamos el Diccionario que le dará valor a los Placeholders\n",
    "        feed_dict = {tensor_x:x, tensor_y:y}\n",
    "\n",
    "        #Entrenamiento del Modelo\n",
    "        for step in range(epochs):\n",
    "\n",
    "            #Ejecutamos el Grafo - Actualización de Datos\n",
    "            session.run(actualizacion_parametros,feed_dict=feed_dict)\n",
    "\n",
    "            #Ejecutamos el Grafo - Predicción del Modelo\n",
    "            predicciones = session.run(prediccion,feed_dict=feed_dict)\n",
    "\n",
    "            #Ejecutamos el Grafo - Resultado de Variables Entrenadas\n",
    "            pendiente_final,intercepto_final = session.run([modelo.m,modelo.b],feed_dict=feed_dict)\n",
    "\n",
    "            #Ejecutamos el Grafo - Datos Escalar\n",
    "            summary = session.run(MSE_summary,feed_dict=feed_dict)\n",
    "\n",
    "            #Almacenamos datos de Scalar - Para Tensorboard\n",
    "            writer.add_summary(summary, step)\n",
    "\n",
    "            #Imprimimos resultados de Variables por entrenamiento - Cada N Entrenamientos\n",
    "            if (step+1) % imprimir_cada == 0:\n",
    "                print(\"Prueba {} - Parámetros finales: m={}  b={}\".format(step+1,pendiente_final,intercepto_final))\n",
    "\n",
    "        # Si queremos imprimir la función de Error - Despues del Entrenamiento \n",
    "        final_error = session.run(funcion_error,feed_dict=feed_dict)\n",
    "        print(\"Error - Despues de Entrenamiento={}\".format(final_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos el Modelo solo para asegurar que no haya errores. Por el momento es con valores pequeños de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prueba 50 - Parámetros finales: m=25.88538360595703  b=3.795400619506836\n",
      "Prueba 100 - Parámetros finales: m=29.268674850463867  b=4.078108310699463\n",
      "Error - Despues de Entrenamiento=1431.6644287109375\n"
     ]
    }
   ],
   "source": [
    "#Usaremos el mismo Learning rate del Proyecto\n",
    "learning_rate = 0.001\n",
    "\n",
    "#Definimos cuantas iteraciones de Entrenamiento haremos\n",
    "epochs=100\n",
    "\n",
    "#Definimos cada cuanto vamos a imprimir\n",
    "imprimir_cada = 50\n",
    "\n",
    "#Ejecutamos la función de Entrenamiento para los parametros definidos\n",
    "Entrenamiento(learning_rate,epochs,imprimir_cada,x_train,y_real)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard - Grafo\n",
    "\n",
    "Vemos como quedo nuestro Grafo en Tensorboard, de acuerdo al modelo definido.\n",
    "\n",
    "<img src=\"assets/Grafo_Tensorboard.png\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard - Scalar\n",
    "\n",
    "El Error obtenido por la función MSE (Mean Squared Error) se puede visualizar en tensorbord de la siguiente manera:\n",
    "\n",
    "<img src=\"assets/Scalar_Tensorboard.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos tambien como en Tensorboard se muestra la prueba con el string de configuración definido, y la diferencia en algunas pruebas ejecutadas en las correciones del modelo.\n",
    "\n",
    "<img src=\"assets/Tensorboard_StringConf.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas de Entrenamiento para Ajuste Parametros Modelo\n",
    "\n",
    "Haremos pruebas para ir ajustando los hyperparametros para el correcto funcionamiento de nuestro modelo.\n",
    "\n",
    "Anteriormente **(Modelo 1)** ejecutamos el entrenamiento con un learning rate de **0.001**, pero solamente ejecutamos **100** pruebas consiguiendo un error de **1431**. Variaremos los parametros para ir consiguiendo mejores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 2\n",
    "\n",
    "No cambiaremos el Learning rate, pero ejecutaremos al menos unas 1000 pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prueba 500 - Parámetros finales: m=30.062368392944336  b=2.2587428092956543\n",
      "Prueba 1000 - Parámetros finales: m=30.42473793029785  b=-0.06219841539859772\n",
      "Error - Despues de Entrenamiento=1406.33251953125\n"
     ]
    }
   ],
   "source": [
    "#Usaremos el mismo Learning rate del Proyecto\n",
    "learning_rate = 0.001\n",
    "\n",
    "#Definimos cuantas iteraciones de Entrenamiento haremos\n",
    "epochs=1000\n",
    "\n",
    "#Definimos cada cuanto vamos a imprimir\n",
    "imprimir_cada = 500\n",
    "\n",
    "#Ejecutamos la función de Entrenamiento para los parametros definidos\n",
    "Entrenamiento(learning_rate,epochs,imprimir_cada,x_train,y_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conseguimos un mejor resultado **(1406)**; pero veo que no es suficiente. Veamos como cambió la grafica en Tensorboard, comparando con el modelo anterior.\n",
    "\n",
    "<img src=\"assets/Scalar_Tensorboard_Modelo2.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 3\n",
    "\n",
    "No cambiaremos el Learning rate, pero ejecutaremos más pruebas, al menos unas 3000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prueba 500 - Parámetros finales: m=30.062368392944336  b=2.2587428092956543\n",
      "Prueba 1000 - Parámetros finales: m=30.42473793029785  b=-0.06219841539859772\n",
      "Prueba 1500 - Parámetros finales: m=30.778564453125  b=-2.3284294605255127\n",
      "Prueba 2000 - Parámetros finales: m=31.12404441833496  b=-4.541244029998779\n",
      "Prueba 2500 - Parámetros finales: m=31.46140480041504  b=-6.701898574829102\n",
      "Prueba 3000 - Parámetros finales: m=31.790790557861328  b=-8.811623573303223\n",
      "Error - Despues de Entrenamiento=1367.0936279296875\n"
     ]
    }
   ],
   "source": [
    "#Usaremos el mismo Learning rate del Proyecto\n",
    "learning_rate = 0.001\n",
    "\n",
    "#Definimos cuantas iteraciones de Entrenamiento haremos\n",
    "epochs=3000\n",
    "\n",
    "#Definimos cada cuanto vamos a imprimir\n",
    "imprimir_cada = 500\n",
    "\n",
    "#Ejecutamos la función de Entrenamiento para los parametros definidos\n",
    "Entrenamiento(learning_rate,epochs,imprimir_cada,x_train,y_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conseguimos un mejor resultado **(1367)**; pero veo que por el ser el Learning rate muy pequeño vamos avanzando muy poco. Veamos como cambió la grafica en Tensorboard, comparando con el modelo anterior.\n",
    "\n",
    "<img src=\"assets/Scalar_Tensorboard_Modelo3.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 4\n",
    "\n",
    "Al ver poco avance con el Learning rate, cambiaremos a un learning rate de 0.01 siempre dejando pruebas 3000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prueba 500 - Parámetros finales: m=33.033206939697266  b=-16.769079208374023\n",
      "Prueba 1000 - Parámetros finales: m=35.66579818725586  b=-33.630496978759766\n",
      "Prueba 1500 - Parámetros finales: m=37.73958969116211  b=-46.91284942626953\n",
      "Prueba 2000 - Parámetros finales: m=39.37319564819336  b=-57.375877380371094\n",
      "Prueba 2500 - Parámetros finales: m=40.6600456237793  b=-65.61799621582031\n",
      "Prueba 3000 - Parámetros finales: m=41.67375564575195  b=-72.11067199707031\n",
      "Error - Despues de Entrenamiento=1194.6534423828125\n"
     ]
    }
   ],
   "source": [
    "#Usaremos el mismo Learning rate del Proyecto\n",
    "learning_rate = 0.01\n",
    "\n",
    "#Definimos cuantas iteraciones de Entrenamiento haremos\n",
    "epochs=3000\n",
    "\n",
    "#Definimos cada cuanto vamos a imprimir\n",
    "imprimir_cada = 500\n",
    "\n",
    "#Ejecutamos la función de Entrenamiento para los parametros definidos\n",
    "Entrenamiento(learning_rate,epochs,imprimir_cada,x_train,y_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conseguimos un mejor resultado **(1194)**; se consiguió un mejor resultado incrementando el learning rate. Veamos como cambió la grafica en Tensorboard, comparando con el modelo anterior.\n",
    "\n",
    "<img src=\"assets/Scalar_Tensorboard_Modelo4.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modelo 5\n",
    "\n",
    "Volveremos a cambiar el Learning rate, dejandolo ahora en 0.1, y por el momento siempre con 3000 pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prueba 500 - Parámetros finales: m=nan  b=nan\n",
      "Prueba 1000 - Parámetros finales: m=nan  b=nan\n",
      "Prueba 1500 - Parámetros finales: m=nan  b=nan\n",
      "Prueba 2000 - Parámetros finales: m=nan  b=nan\n",
      "Prueba 2500 - Parámetros finales: m=nan  b=nan\n",
      "Prueba 3000 - Parámetros finales: m=nan  b=nan\n",
      "Error - Despues de Entrenamiento=nan\n"
     ]
    }
   ],
   "source": [
    "#Usaremos el mismo Learning rate del Proyecto\n",
    "learning_rate = 0.1\n",
    "\n",
    "#Definimos cuantas iteraciones de Entrenamiento haremos\n",
    "epochs=3000\n",
    "\n",
    "#Definimos cada cuanto vamos a imprimir\n",
    "imprimir_cada = 500\n",
    "\n",
    "#Ejecutamos la función de Entrenamiento para los parametros definidos\n",
    "Entrenamiento(learning_rate,epochs,imprimir_cada,x_train,y_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí vemos que con este Learning rate, no se encontró divergencia. Debemos probar un learning rate menor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modelo 6\n",
    "\n",
    "El Learning rate anterior fue muy alto, lo rebajaremos a 0.05 y por el momento siempre con 3000 pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prueba 500 - Parámetros finales: m=-110.8829345703125  b=-89.3142318725586\n",
      "Prueba 1000 - Parámetros finales: m=-729.5380249023438  b=-207.72073364257812\n",
      "Prueba 1500 - Parámetros finales: m=-3903.27099609375  b=-709.8502197265625\n",
      "Prueba 2000 - Parámetros finales: m=-20107.7109375  b=-3241.874267578125\n",
      "Prueba 2500 - Parámetros finales: m=-102818.453125  b=-16156.212890625\n",
      "Prueba 3000 - Parámetros finales: m=-524986.5  b=-82069.34375\n",
      "Error - Despues de Entrenamiento=5656783880192.0\n"
     ]
    }
   ],
   "source": [
    "#Usaremos el mismo Learning rate del Proyecto\n",
    "learning_rate = 0.05\n",
    "\n",
    "#Definimos cuantas iteraciones de Entrenamiento haremos\n",
    "epochs=3000\n",
    "\n",
    "#Definimos cada cuanto vamos a imprimir\n",
    "imprimir_cada = 500\n",
    "\n",
    "#Ejecutamos la función de Entrenamiento para los parametros definidos\n",
    "Entrenamiento(learning_rate,epochs,imprimir_cada,x_train,y_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí vemos que con este Learning rate tampoco funcionó correctamente, mucha divergencia, consiguiendo valores de error muy altos. Veamos como cambió la grafica en Tensorboard, comparando con los modelos anteriores. \n",
    "\n",
    "<img src=\"assets/Scalar_Tensorboard_Modelo6.png\">\n",
    "\n",
    "Debemos probar un learning rate menor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modelo 7\n",
    "\n",
    "El Learning rate anterior fue muy alto, lo rebajaremos a 0.04 y por el momento siempre con 3000 pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prueba 500 - Parámetros finales: m=39.3773307800293  b=-57.402374267578125\n",
      "Prueba 1000 - Parámetros finales: m=43.104515075683594  b=-81.27448272705078\n",
      "Prueba 1500 - Parámetros finales: m=44.53873062133789  b=-90.46044921875\n",
      "Prueba 2000 - Parámetros finales: m=45.09061050415039  b=-93.99517822265625\n",
      "Prueba 2500 - Parámetros finales: m=45.302982330322266  b=-95.3553466796875\n",
      "Prueba 3000 - Parámetros finales: m=45.38468933105469  b=-95.87870025634766\n",
      "Error - Despues de Entrenamiento=1180.4698486328125\n"
     ]
    }
   ],
   "source": [
    "#Usaremos el mismo Learning rate del Proyecto\n",
    "learning_rate = 0.04\n",
    "\n",
    "#Definimos cuantas iteraciones de Entrenamiento haremos\n",
    "epochs=3000\n",
    "\n",
    "#Definimos cada cuanto vamos a imprimir\n",
    "imprimir_cada = 500\n",
    "\n",
    "#Ejecutamos la función de Entrenamiento para los parametros definidos\n",
    "Entrenamiento(learning_rate,epochs,imprimir_cada,x_train,y_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conseguimos un mejor resultado **(1180.46)**; se consiguió un mejor resultado con el learning rate de 0.04 que con los modelos anteriores. Veamos como cambió la grafica en Tensorboard, comparando con los modelos de 0.001, 0.01.\n",
    "\n",
    "<img src=\"assets/Scalar_Tensorboard_Modelo7.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modelo 8\n",
    "\n",
    "Mantendremos el learning rate de 0.04, pero ahora aumentaremos las pruebas a 4000 para ver si mejora el modelo con más pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prueba 1000 - Parámetros finales: m=43.104515075683594  b=-81.27448272705078\n",
      "Prueba 2000 - Parámetros finales: m=45.09061050415039  b=-93.99517822265625\n",
      "Prueba 3000 - Parámetros finales: m=45.38468933105469  b=-95.87870025634766\n",
      "Prueba 4000 - Parámetros finales: m=45.42823028564453  b=-96.15756225585938\n",
      "Error - Despues de Entrenamiento=1180.4676513671875\n"
     ]
    }
   ],
   "source": [
    "#Usaremos el mismo Learning rate del Proyecto\n",
    "learning_rate = 0.04\n",
    "\n",
    "#Definimos cuantas iteraciones de Entrenamiento haremos\n",
    "epochs=4000\n",
    "\n",
    "#Definimos cada cuanto vamos a imprimir\n",
    "imprimir_cada = 1000\n",
    "\n",
    "#Ejecutamos la función de Entrenamiento para los parametros definidos\n",
    "Entrenamiento(learning_rate,epochs,imprimir_cada,x_train,y_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se podría decir que se consiguió los mismos resultados que con 3000 pruebas **(1180.46)**; hubo una mejora en centecimos de decimal, pero a mi parecer no valdría la pena. Veamos como cambió la grafica en Tensorboard, comparando con los modelos de 0.001, 0.01, 0.04 (3000 Pruebas).\n",
    "\n",
    "<img src=\"assets/Scalar_Tensorboard_Modelo8.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modelo 9\n",
    "\n",
    "Mantendremos el learning rate de 0.04, pero ahora reduciremos a 2000 para ver si este número es suficiente para conseguir los resultados conseguido en el modelo 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prueba 500 - Parámetros finales: m=39.3773307800293  b=-57.402374267578125\n",
      "Prueba 1000 - Parámetros finales: m=43.104515075683594  b=-81.27448272705078\n",
      "Prueba 1500 - Parámetros finales: m=44.53873062133789  b=-90.46044921875\n",
      "Prueba 2000 - Parámetros finales: m=45.09061050415039  b=-93.99517822265625\n",
      "Error - Despues de Entrenamiento=1180.5867919921875\n"
     ]
    }
   ],
   "source": [
    "#Usaremos el mismo Learning rate del Proyecto\n",
    "learning_rate = 0.04\n",
    "\n",
    "#Definimos cuantas iteraciones de Entrenamiento haremos\n",
    "epochs=2000\n",
    "\n",
    "#Definimos cada cuanto vamos a imprimir\n",
    "imprimir_cada = 500\n",
    "\n",
    "#Ejecutamos la función de Entrenamiento para los parametros definidos\n",
    "Entrenamiento(learning_rate,epochs,imprimir_cada,x_train,y_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con menos pruebas, no se consiguio un mejor resultado que el modelo 7. Tiene un valor cercano pero se puede mejorar con mas pruebas. No se muestra la gráfica de tensorboard, porque a nivel visual no hay mayor diferencia a la grafica anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modelo 10\n",
    "\n",
    "Mantendremos el learning rate de 0.04, pero ahora aumentaremos las pruebas a 2500 para ver si este número es suficiente para conseguir los resultados conseguido en el modelo 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prueba 500 - Parámetros finales: m=39.3773307800293  b=-57.402374267578125\n",
      "Prueba 1000 - Parámetros finales: m=43.104515075683594  b=-81.27448272705078\n",
      "Prueba 1500 - Parámetros finales: m=44.53873062133789  b=-90.46044921875\n",
      "Prueba 2000 - Parámetros finales: m=45.09061050415039  b=-93.99517822265625\n",
      "Prueba 2500 - Parámetros finales: m=45.302982330322266  b=-95.3553466796875\n",
      "Error - Despues de Entrenamiento=1180.484619140625\n"
     ]
    }
   ],
   "source": [
    "#Usaremos el mismo Learning rate del Proyecto\n",
    "learning_rate = 0.04\n",
    "\n",
    "#Definimos cuantas iteraciones de Entrenamiento haremos\n",
    "epochs=2500\n",
    "\n",
    "#Definimos cada cuanto vamos a imprimir\n",
    "imprimir_cada = 500\n",
    "\n",
    "#Ejecutamos la función de Entrenamiento para los parametros definidos\n",
    "Entrenamiento(learning_rate,epochs,imprimir_cada,x_train,y_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con 2500 pruebas, casí se consiguio el mismo resultado que el modelo 7. Tiene un valor cercano pero se puede mejorar con mas pruebas. No se muestra la gráfica de tensorboard, porque a nivel visual no hay mayor diferencia a la grafica del modelo 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "Despues de efectuar muchas pruebas, variando número de pruebas, learning rate; el Modelo que más se ajusta sería **Modelo #7**. Los datos serían:\n",
    "* Learning rate = 0.04\n",
    "* EPOCHS = 3000\n",
    "* Pendiente (m) = 45.38468933105469\n",
    "* Intercepto (b) =-95.87870025634766\n",
    "* MSE al Finalizar la Prueba = 1180.46\n",
    "\n",
    "La función para la variable Overall quedaria de la siguiente manera: y = 45.38468933105469x -95.87870025634766\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
