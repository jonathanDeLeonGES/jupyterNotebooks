{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Curso\n",
    "\n",
    "Desarrollo del proyecto Final para el Curso de Statistical Learning -  Segundo Trimestre Maestria en Ciencia de Datos- Universidad Galileo.\n",
    "\n",
    "Este Notebook en específico servirá el Deployment de Modelos ya entrenados para la predicción del Problema \"Predicción de Supervivencia Titanic\". En un Notebook diferente se hizo el Entrenamiento/Validación de los modelos que aquí se usaran para la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Referencia a Librerias que usaremos en este notebook\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn import tree\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos los Modelos Entrenados\n",
    "\n",
    "Los modelos entrenados y definidos en el notebook anterior, se cargaran.\n",
    "\n",
    "Enlace Notebook donde se implementan los modelos:\n",
    "https://github.com/jonathanDeLeonGES/jupyterNotebooks/blob/master/Proyecto%20Statistical%20Learning/Proyecto%20-%20Titanic%20-%20Modelos.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Modelo - DecisionTree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=0, splitter='best')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Tomamos el Clasificador con mejores resultados\n",
    "DT_Classifier = pickle.load( open( \"DumpDT/20200629_225218_DecisionTree_max_depth=5.p\", \"rb\" ) )\n",
    "DT_Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modelo - SVM (Support Vector Machine) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Tomamos el Clasificador con mejores resultados\n",
    "SVM_Classifier = pickle.load( open( \"DumpSVM/20200629_225241_SVM_random_state=None_tol=0.001_C=1_degree=3_max_iter=-1.p\", \"rb\" ) )\n",
    "SVM_Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Modelo - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.NaiveBayes at 0x167b8863a08>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Tomamos el Clasificador con mejores resultados\n",
    "NB_Classifier = pickle.load( open( \"DumpNB/20200629_195113_NaiveBayes_alpha=1.p\", \"rb\" ) )\n",
    "NB_Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modelo - Regresión Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4022264 ],\n",
       "       [-0.27672705],\n",
       "       [-0.04158774],\n",
       "       [ 0.16427359],\n",
       "       [-1.1317778 ],\n",
       "       [ 0.0348492 ],\n",
       "       [-0.01437835],\n",
       "       [-0.11370662],\n",
       "       [-0.4203568 ],\n",
       "       [ 0.03524392],\n",
       "       [ 0.45458624]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Tomamos el Clasificador con mejores resultados\n",
    "RL_Weights = np.load(\"DumpRL/20200629_225424_MiniBatch_GD_Lr=0.1_reg=0.01_reg_Type=L2_BatchSize=50.npy\",allow_pickle=True)\n",
    "RL_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementamos de una vez, la función de predicción para el modelo con Regresión logistica, ya que a diferencia de los otros, este no cuenta aún con su función de predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def predicciónRL(weights,x):\n",
    "    '''Defimos función generico para la predicción de la Regresión Logistica'''\n",
    "    #Determinamos los logits\n",
    "    logits= np.matmul(x, weights)\n",
    "    #Determinamos la predicción con Sigmoid\n",
    "    predict = np.round(sigmoid(logits))\n",
    "    ##Retornamos la predicción\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización de los Datos\n",
    "\n",
    "Cargaremos los objetos(scalers) que nos servirán para transformar/Normalizar la data que vamos a buscar predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Cargamos el Normalizador Standar\n",
    "Standar_Scaler = pickle.load( open( \"DumpScalers/StandarScaler.p\", \"rb\" ) )\n",
    "Standar_Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Cargamos el Normalizador MinMax\n",
    "MinMax_Scaler = pickle.load( open( \"DumpScalers/MinMaxScaler.p\", \"rb\" ) )\n",
    "MinMax_Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de Predicción - Solo una Observación\n",
    "\n",
    "Crearemos la función para la predicción de una sola observación, combinando los modelos que ya cargamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediccionObservacion(x):\n",
    "    \n",
    "    #Antes de Cualquier cosa - Se normalizará la observación\n",
    "    #Standard\n",
    "    x_st = Standar_Scaler.transform(x)\n",
    "    #MinMax -> Funciona mejor para Naive Bayes\n",
    "    x_mm = MinMax_Scaler.transform(x)\n",
    "    #Predicción Sobre la observacion - DecisionTree \n",
    "    y_pred_test_DT = DT_Classifier.predict(x_st)\n",
    "    #Predicción Sobre la observacion - SVM\n",
    "    y_pred_test_SVM = SVM_Classifier.predict(x_st)\n",
    "    #Predicción Sobre la observacion - NB\n",
    "    y_pred_test_NB = NB_Classifier.predict(x_mm)\n",
    "    #Predicción Sobre la observacion - RL\n",
    "    y_pred_test_RL = predicciónRL(RL_Weights,x_st)\n",
    "    \n",
    "    ##Usamos Ensemble y tomamos la predicción por votación\n",
    "    predicciones = []\n",
    "    predicciones.append(np.array(y_pred_test_DT).reshape(90))\n",
    "    predicciones.append(np.array(y_pred_test_SVM).reshape(90))\n",
    "    predicciones.append(np.array(y_pred_test_NB).reshape(90))\n",
    "    predicciones.append(np.array(y_pred_test_RL).reshape(90))\n",
    "    y_pred_test_final= stats.mode(predicciones)[0]\n",
    "    \n",
    "    print(\"La predicción para esta observación es:{}\".format(y_pred_test_final))\n",
    "    \n",
    "    ##Además de la predicción se necesita mostrar otros datos\n",
    "    \n",
    "    ##Mostramos el Arbol de decision\n",
    "    feature_names = np.array(x.columns)\n",
    "    target_names = np.array(['Dead', 'Survived'])\n",
    "    tree.plot_tree(DT_Classifier,feature_names = feature_names,class_names= target_names,filled=True) \n",
    "    \n",
    "    ##La regresión Probabilistica de Bayes\n",
    "    print(\"La predicción probabilistica con el Metodo Naive Bayes es:{}\".format(NB_Classifier.predict_proba(x_mm)))\n",
    "    \n",
    "    ##La regresión Logistica \n",
    "    print(\"La predicción probabilistica con Regresión Logistica es:{}\".format(sigmoid(np.matmul(x, weights))))\n",
    "    \n",
    "    ##Se devolverá la predicción, aunque ya fue mostrada por medio de un print\n",
    "    return y_pred_test_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba de Función de Predicción\n",
    "\n",
    "Tal como sugiere el proyecto, se probará la función de predicción con 10 observaciones (1 a una)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Cargaremos 10 datos random del dataset que ya se tenia del Titanic\n",
    "data = pd.read_csv(\"data_titanic_proyecto.csv\")\n",
    "X = data.drop(['passenger_survived','PassengerId','Name','Ticket','Cabin'], axis=1)\n",
    "Y = data['passenger_survived'].values\n",
    "##Por facilidad ponemos datos por defecto en los registros con NA - Ya que excede el objetivo de la prueba\n",
    "X[data['Embarked'].isna()]='S'\n",
    "X[data['Age'].isna()]=29\n",
    "##Obtenemos un dataset con 10 observaciones que nos servira para la pruebas\n",
    "X_test, Y_test = resample(X, Y , n_samples = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
