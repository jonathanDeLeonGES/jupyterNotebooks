{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practica 4 - XOR con Composición y Perceptrones\n",
    "\n",
    "## Parte 1\n",
    "\n",
    "Basado en las operaciones conocidads(not,or,and), crear una función “xor” de manera manual a través de la composición de múltiples perceptrones.\n",
    "\n",
    "1) Creamos funciones para las operaciones básicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada 0 -> Salida  1\n",
      "Entrada 1 -> Salida  0\n"
     ]
    }
   ],
   "source": [
    "#Función Not - Negación\n",
    "def operacion_not(x):\n",
    "    \n",
    "    #Parametros del Modelo - Definidos manualmente\n",
    "    parametros = [-1 , 1 ]\n",
    "    \n",
    "    #Devolvemos el resultado\n",
    "    return  int(x*parametros[0]  +  parametros[1]>0)\n",
    "\n",
    "#Prueba de la Función creada\n",
    "print('Entrada 0 -> Salida ',operacion_not(0))\n",
    "print('Entrada 1 -> Salida ',operacion_not(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada (0,0) -> Salida  0\n",
      "Entrada (0,1) -> Salida  1\n",
      "Entrada (1,0) -> Salida  1\n",
      "Entrada (1,1) -> Salida  1\n"
     ]
    }
   ],
   "source": [
    "#Función OR - O Lógico\n",
    "def  operacion_or(x1,x2):\n",
    "    #Parametros del Modelo - Definidos manualmente\n",
    "    parametros = [1,1,0]\n",
    "    \n",
    "    #Devolvemos el resultado\n",
    "    return  int(x1*parametros[0]  + x2*parametros[1] + parametros[2] > 0)\n",
    "\n",
    "#Prueba de la Función creada\n",
    "print('Entrada (0,0) -> Salida ',operacion_or(0,0))\n",
    "print('Entrada (0,1) -> Salida ',operacion_or(0,1))\n",
    "print('Entrada (1,0) -> Salida ',operacion_or(1,0))\n",
    "print('Entrada (1,1) -> Salida ',operacion_or(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada (0,0) -> Salida  0\n",
      "Entrada (0,1) -> Salida  0\n",
      "Entrada (1,0) -> Salida  0\n",
      "Entrada (1,1) -> Salida  1\n"
     ]
    }
   ],
   "source": [
    "#Función AND - Y Lógico\n",
    "def  operacion_and(x1,x2):\n",
    "    #Parametros del Modelo - Definidos manualmente\n",
    "    parametros = [1,1,-1]\n",
    "    \n",
    "    #Devolvemos el resultado\n",
    "    return  int(x1*parametros[0]  + x2*parametros[1] + parametros[2] > 0)\n",
    "\n",
    "#Prueba de la Función creada\n",
    "print('Entrada (0,0) -> Salida ',operacion_and(0,0))\n",
    "print('Entrada (0,1) -> Salida ',operacion_and(0,1))\n",
    "print('Entrada (1,0) -> Salida ',operacion_and(1,0))\n",
    "print('Entrada (1,1) -> Salida ',operacion_and(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) En base a las funciones anteriores, se crea la función XOR (Compuesta de las funciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada (0,0) -> Salida  0\n",
      "Entrada (0,1) -> Salida  1\n",
      "Entrada (1,0) -> Salida  1\n",
      "Entrada (1,1) -> Salida  0\n"
     ]
    }
   ],
   "source": [
    "#Función XOR - O Exclusivo\n",
    "def operacion_xor(x1,x2):\n",
    "\n",
    "    #Efectuamos algunas operaciones logicas sobre los parametros recibidos\n",
    "    operation_and= operacion_and(x1,x2)\n",
    "    operation_or = operacion_or(x1,x2)\n",
    "\n",
    "    #Negamos And\n",
    "    operation_nand = operacion_not(operation_and)\n",
    "    \n",
    "    #Calculamos el XOR como el AND de las operaciones NAND y OR\n",
    "    return operacion_and(operation_nand,operation_or)\n",
    "\n",
    "#Prueba de la Función creada\n",
    "print('Entrada (0,0) -> Salida ',operacion_xor(0,0))\n",
    "print('Entrada (0,1) -> Salida ',operacion_xor(0,1))\n",
    "print('Entrada (1,0) -> Salida ',operacion_xor(1,0))\n",
    "print('Entrada (1,1) -> Salida ',operacion_xor(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2\n",
    "\n",
    "Usando activación \"step\" y el algoritmo de entrenamiento de perceptrones visto en clase, entrenar :  \n",
    "1) Perceptrón para la operación \"and\"  \n",
    "2) Perceptrón para la operación \"or\"  \n",
    "Remplazar las funciones de la parte 1 con los perceptrones entrenados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una función que nos permita entrenar el perceptron.\n",
    "Aquí no se usará un algoritmo como Gradiend descent, se usará el algoritmo simple de entrenamiento de perceptron mostrado en clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos las librerias que nos serviran para el modelo\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función de Entrenamiento Perceptron\n",
    "def entrenamientoPerceptron(x,y,lr):\n",
    "    '''Utilizamos el Algoritmo de Entrenamiento de un Perceptron'''\n",
    "    '''No se utiliza Gradiend Descent o cualquier otra tecnica de ML para el entrenamiento'''\n",
    "    \n",
    "    #Recibimos como entrada en la variable X la matriz con los features \n",
    "    #Recibimos los resultados buscados en la variable Y\n",
    "    #Recibimos el Learning rate\n",
    "    \n",
    "    #Para que la operación sea vectorizada, agregamos una columna en X con el valor 1 para el Bias\n",
    "    x_train = np.ones((x.shape[0],x.shape[1]+1))\n",
    "    x_train[:,:-1]=x \n",
    "    \n",
    "    #En base a los features será la cantidad de parametros a entrenar + 1 para incluir el Bias\n",
    "    #Asignamos los pesos de forma Random, con valores de una distribución normal \n",
    "    mu, sigma = 0, 1 # media y Desviación estandar\n",
    "    parametros = np.array(np.round(np.random.normal(mu, sigma, x.shape[1]+1),2)).reshape(-1,1)\n",
    "\n",
    "    #Variable que servirá para determinar si ya se encontro convergencia en el modelo\n",
    "    convergencia = False\n",
    "    #Mientras no haya convergencia - Se sigue entrenando el modelo\n",
    "    while(not(convergencia)):\n",
    "        #Recorremos cada dato de entrenamiento\n",
    "        for i in range(0,len(x)):\n",
    "            #Vemos el valor del Label Y\n",
    "            y_real = y[i]\n",
    "            \n",
    "            #Calculamos la función de x\n",
    "            f_x=np.matmul(x_train[i],parametros)\n",
    "        \n",
    "            #Si el resultado Real es 1, pero el calculado es menor que cero\n",
    "            if y_real==1 and f_x<=0:\n",
    "                #Actualizamos los valores de los parametros\n",
    "                parametros= parametros + np.array(x_train[i]).reshape(-1,1)*lr\n",
    "            elif y_real==0 and f_x>0:\n",
    "                parametros= parametros - np.array(x_train[i]).reshape(-1,1)*lr\n",
    "\n",
    "        #Evaluamos si hay convergencia\n",
    "        y_hat = np.matmul(x_train,parametros)\n",
    "        #Pasamos la función de activación por medio del np.where para que sea vectorizada\n",
    "        y_hat = np.where(y_hat < 0, 0, 1)\n",
    "\n",
    "        #Evaluamos si hay convergencia\n",
    "        convergencia = (y_hat ==y).all()\n",
    "    #Devolvemos los parametros entrenados\n",
    "    return parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una función generica que nos permita implementar la operación entrenada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función que nos permita implementar la función entrenada con el perceptron\n",
    "def operacion_percepton(parametros,x):\n",
    "    \n",
    "    #Se implementaran funciones vectorizadas\n",
    "    #Le agregamos el X una columna con valor 1, para la operación del Bias\n",
    "    x_operacion = np.ones((x.shape[0],x.shape[1]+1))\n",
    "    x_operacion[:,:-1]=x \n",
    "    \n",
    "    #Efectuamos la operación\n",
    "    y_hat=np.matmul(x_operacion,parametros)\n",
    "    \n",
    "    #Devolvemos el resultado - Con la función de activación\n",
    "    return  np.where(y_hat < 0, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron AND\n",
    "\n",
    "Con la función de entrenamiento, entrenaremos nuestro perceptron para que nos devuelva los parametros que nos permitan implementar la función **AND**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24]x1 +[0.13]x2 + [-0.29]\n"
     ]
    }
   ],
   "source": [
    "#Seteamos los valores de entrenamiento\n",
    "x = np.array(((0,0),(0,1),(1,0),(1,1)))\n",
    "#Los valores buscados\n",
    "y = np.array(((0),(0),(0),(1))).reshape(-1,1)\n",
    "#Definimos el Learning rate\n",
    "lr=0.1\n",
    "#Entrenamos el Perceptron\n",
    "parametros= entrenamientoPerceptron(x,y,lr)\n",
    "\n",
    "#La función quedaria:\n",
    "print(\"{}x1 +{}x2 + {}\".format(parametros[0],parametros[1],parametros[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos los parametros entrenados y comprobamos si logramos implementar la función *AND*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado Prueba completa Vectorizada\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      "Pruebas de Forma individual\n",
      "Entrada (0,0) -> Salida  [[0]]\n",
      "Entrada (0,1) -> Salida  [[0]]\n",
      "Entrada (1,0) -> Salida  [[0]]\n",
      "Entrada (1,1) -> Salida  [[1]]\n"
     ]
    }
   ],
   "source": [
    "#Con los parametros anteriores y el vector X se prueba la operación\n",
    "result_vector=operacion_percepton(parametros,x)\n",
    "print('Resultado Prueba completa Vectorizada')\n",
    "print(result_vector)\n",
    "\n",
    "#Probamos la función de forma individual\n",
    "print('Pruebas de Forma individual')\n",
    "print('Entrada (0,0) -> Salida ',operacion_percepton(parametros,np.array((0,0)).reshape(1,-1)))\n",
    "print('Entrada (0,1) -> Salida ',operacion_percepton(parametros,np.array((0,1)).reshape(1,-1)))\n",
    "print('Entrada (1,0) -> Salida ',operacion_percepton(parametros,np.array((1,0)).reshape(1,-1)))\n",
    "print('Entrada (1,1) -> Salida ',operacion_percepton(parametros,np.array((1,1)).reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron OR\n",
    "\n",
    "Con la función de entrenamiento, entrenaremos nuestro perceptron para que nos devuelva los parametros que nos permitan implementar la función **OR**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63]x1 +[0.09]x2 + [-0.08]\n"
     ]
    }
   ],
   "source": [
    "#Seteamos los valores de entrenamiento\n",
    "x = np.array(((0,0),(0,1),(1,0),(1,1)))\n",
    "#Los valores buscados\n",
    "y = np.array(((0),(1),(1),(1))).reshape(-1,1)\n",
    "#Definimos el Learning rate\n",
    "lr=0.1\n",
    "#Entrenamos el Perceptron\n",
    "parametros= entrenamientoPerceptron(x,y,lr)\n",
    "\n",
    "#La función quedaria:\n",
    "print(\"{}x1 +{}x2 + {}\".format(parametros[0],parametros[1],parametros[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos los parametros entrenados y comprobamos si logramos implementar la función *OR*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado Prueba completa Vectorizada\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Pruebas de Forma individual\n",
      "Entrada (0,0) -> Salida  [[0]]\n",
      "Entrada (0,1) -> Salida  [[1]]\n",
      "Entrada (1,0) -> Salida  [[1]]\n",
      "Entrada (1,1) -> Salida  [[1]]\n"
     ]
    }
   ],
   "source": [
    "#Con los parametros anteriores y el vector X se prueba la operación\n",
    "result_vector=operacion_percepton(parametros,x)\n",
    "print('Resultado Prueba completa Vectorizada')\n",
    "print(result_vector)\n",
    "\n",
    "#Probamos la función de forma individual\n",
    "print('Pruebas de Forma individual')\n",
    "print('Entrada (0,0) -> Salida ',operacion_percepton(parametros,np.array((0,0)).reshape(1,-1)))\n",
    "print('Entrada (0,1) -> Salida ',operacion_percepton(parametros,np.array((0,1)).reshape(1,-1)))\n",
    "print('Entrada (1,0) -> Salida ',operacion_percepton(parametros,np.array((1,0)).reshape(1,-1)))\n",
    "print('Entrada (1,1) -> Salida ',operacion_percepton(parametros,np.array((1,1)).reshape(1,-1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
